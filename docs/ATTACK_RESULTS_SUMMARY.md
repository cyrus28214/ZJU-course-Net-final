# 对抗攻击测试结果总结

## 测试配置

- **模型**: MNIST语义通信系统
- **压缩率**: 0.1 (78维语义特征)
- **设备**: NVIDIA GeForce RTX 5070 (CUDA)
- **测试数据**: MNIST测试集，100个样本
- **干净样本准确率**: 99.00%

## 攻击结果

### 1. FGSM攻击 (Fast Gradient Sign Method)

单步梯度符号攻击，快速但效果较弱。

| Epsilon | 对抗准确率 | 攻击成功率 | L2扰动 | L∞扰动 | PSNR (dB) | 语义距离 |
|---------|-----------|-----------|--------|--------|-----------|----------|
| 0.1     | 85.00%    | **15.00%** | 2.09   | 0.10   | 22.54     | 0.0443   |
| 0.2     | 36.00%    | **64.00%** | 4.14   | 0.20   | 16.59     | 0.0883   |
| 0.3     | 8.00%     | **92.00%** | 6.17   | 0.30   | 13.13     | 0.1320   |

**分析**:
- ε=0.1时攻击效果有限（15%成功率）
- ε=0.2时攻击效果显著（64%成功率）
- ε=0.3时攻击非常成功（92%成功率）
- 随着扰动增大，图像质量下降（PSNR降低）

### 2. PGD攻击 (Projected Gradient Descent)

迭代式攻击（40次迭代），比FGSM更强大。

| Epsilon | 对抗准确率 | 攻击成功率 | L2扰动 | L∞扰动 | PSNR (dB) | 语义距离 |
|---------|-----------|-----------|--------|--------|-----------|----------|
| 0.1     | 69.00%    | **31.00%** | 2.07   | 0.10   | 22.62     | 0.0436   |
| 0.2     | 2.00%     | **98.00%** | 4.01   | 0.20   | 16.87     | 0.0894   |
| 0.3     | 0.00%     | **100.00%** | 5.53  | 0.30   | 14.08     | 0.1215   |

**分析**:
- PGD攻击明显强于FGSM
- ε=0.2时达到98%成功率
- ε=0.3时实现100%攻击成功率（完全破坏分类）
- 语义特征受到显著扰动

### 3. 端到端攻击 (End-to-End Attack)

优化整个编码-解码-分类流程，平衡攻击效果和图像质量。

| 配置 | 对抗准确率 | 攻击成功率 | L2扰动 | L∞扰动 | PSNR (dB) | 语义距离 |
|------|-----------|-----------|--------|--------|-----------|----------|
| ε=0.3, 40 iter | 76.00% | **24.00%** | 1.28 | 0.30 | 20.86 | 0.0515 |

**分析**:
- 攻击成功率较低（24%），但图像质量保持较好（PSNR=20.86）
- L2扰动最小（1.28），说明扰动更加优化
- 语义距离最小（0.0515），说明语义特征变化较小

## 关键发现

### 1. 攻击效果对比

**PGD > FGSM > 端到端攻击**

- **PGD**: 最强攻击，ε=0.3时100%成功率
- **FGSM**: 中等攻击，ε=0.3时92%成功率
- **端到端**: 最温和，但图像质量最好

### 2. 扰动大小 vs 攻击成功率

```
ε=0.1: 低成功率 (15-31%)，图像质量好 (PSNR>22dB)
ε=0.2: 高成功率 (64-98%)，图像质量中等 (PSNR~16dB)
ε=0.3: 极高成功率 (92-100%)，图像质量较差 (PSNR~13dB)
```

### 3. 语义通信系统的脆弱性

- **语义特征易受攻击**: 即使小的输入扰动（ε=0.2）也能显著改变语义特征
- **编码-解码过程不稳定**: 对抗样本经过编解码后仍能误导分类器
- **压缩率影响**: 当前测试使用0.1压缩率（78维特征），较低维度可能更脆弱

### 4. 实际威胁场景

语义通信系统在以下场景中可能面临安全风险：
- **智慧城市**: 图像识别系统被对抗样本欺骗
- **自动驾驶**: 交通标志识别错误
- **医疗诊断**: 医学图像分析被干扰
- **工业检测**: 缺陷检测失效

## 可视化结果

### FGSM攻击示例
![FGSM攻击结果](attack_results_fgsm.png)

**观察**:
- 第1行: 干净图像，分类正确
- 第2行: 对抗样本（ε=0.3），多数分类错误
  - 数字2 → 被识别为3
  - 数字1 → 被识别为8
  - 数字0 → 被识别为7
  - 数字4 → 被识别为9
- 第3行: 扰动可视化（放大10倍），显示添加的噪声模式

### PGD攻击示例
![PGD攻击结果](attack_results_pgd.png)

**观察**:
- PGD攻击生成的对抗样本更加"优化"
- 扰动分布更加均匀
- 攻击成功率更高（100%）

## 防御建议

### 1. 对抗训练
在训练过程中加入对抗样本，提高模型鲁棒性。

### 2. 输入预处理
- 随机化输入（添加随机噪声）
- 图像平滑/去噪

### 3. 检测机制
- 监测语义特征的异常变化
- 添加对抗样本检测器

### 4. 冗余验证
- 使用多个模型进行交叉验证
- 添加置信度阈值

### 5. 增加语义特征维度
测试更高压缩率（0.2, 0.3）的鲁棒性。

## 下一步研究方向

1. ✅ **完成**: 白盒攻击（FGSM, PGD, 端到端）
2. 🔜 **待测试**: 不同压缩率（0.2, 0.3）下的攻击效果
3. 🔜 **待测试**: 不同SNR下的攻击鲁棒性
4. 🔜 **待实现**: 黑盒攻击（基于查询、迁移攻击）
5. 🔜 **待研究**: 防御方法的有效性

## 文件位置

- **可视化结果**: 
  - `attack_results_fgsm.png`
  - `attack_results_pgd.png`
- **测试脚本**: `test_attack.py`
- **攻击代码**: `attacks/` 目录
- **训练模型**: `saved_model/` 目录

## 结论

本次实验成功验证了**语义通信系统对对抗攻击的脆弱性**：

1. **高攻击成功率**: PGD攻击在ε=0.3时达到100%成功率
2. **小扰动高效果**: 相对较小的扰动（ε=0.2）即可达到64-98%成功率
3. **语义特征不稳定**: 对抗样本显著改变语义特征
4. **实际安全威胁**: 在安全关键应用中需要考虑对抗攻击防护

**建议**: 在部署语义通信系统到实际应用前，必须考虑对抗攻击防御措施。

