# 语义通信系统安全性探索实验报告

## 一、实验背景与目的

### 1.1 研究背景

从1G到5G，通信技术已从模拟语音信号传输发展到高速率、低延迟的多媒体服务。然而，现有技术在支持Beyond-5G (B5G)的智能应用（如脑机接口、增强现实、车联网）时仍面临挑战。为此，研究人员提出了**语义通信（Semantic Communication）**技术。

#### 语义通信的核心思想

传统通信关注比特级准确性，而语义通信专注于语义信息的传递：

- **编码端**：提取图像语义特征（如将28×28=784维图像压缩为78维语义特征）
- **传输**：通过信道传输低维语义特征
- **解码端**：从语义特征重建图像用于分类任务

**优势**：
1. **低延迟**：传输数据量大幅减少（压缩率0.1时，从784维降至78维，压缩90%）
2. **高信噪比容忍度**：关注语义而非比特精确性

#### 安全性挑战

语义通信系统依赖深度学习技术，这使其容易受到**对抗样本攻击**的威胁。考虑到语义通信可能应用于智慧城市、自动驾驶等安全关键领域，研究其安全性至关重要。

### 1.2 实验目的

1. **部署语义通信系统**：实现基于MNIST手写数字识别的语义通信系统
2. **实施对抗攻击**：在白盒场景下生成对抗样本，欺骗通信系统
3. **评估系统脆弱性**：量化分析不同攻击方法的效果
4. **探索防御方向**：提出潜在的防御策略

## 二、实验环境与配置

### 2.1 硬件环境

- **GPU**: NVIDIA GeForce RTX 5070 (12GB显存)
- **CPU**: Intel/AMD 处理器
- **内存**: 16GB+
- **操作系统**: Windows 11

### 2.2 软件环境

```
Python: 3.13.9
PyTorch: 2.9.0+cu130 (CUDA 13.0支持)
Torchvision: 0.24.0+cu130
NumPy: 2.3.4
Matplotlib: 3.10.7
Pandas: 2.3.3
Scipy: 1.16.3
```

### 2.3 系统架构

#### 语义通信系统组成

```
发送端                信道              接收端
┌────────┐       ┌──────────┐      ┌────────┐       ┌────────┐
│原始图像│  -->  │  编码器  │ -->  │  信道  │ -->  │ 解码器 │ --> │分类器│
│28x28  │       │ 784→78  │      │SNR=10dB│      │ 78→784 │     │ 10类 │
└────────┘       └──────────┘      └──────────┘      └────────┘     └────────┘
```

#### 模型结构

**1. 分类器 (MLP_MNIST)**
```
输入: 784维 (28×28图像)
FC1: 784 → 500 (ReLU)
FC2: 500 → 250 (ReLU)
FC3: 250 → 125 (ReLU)
FC4: 125 → 10  (Softmax)
输出: 10类概率分布
```

**2. 编码器-解码器 (MLP_Encoder_Decoder)**

编码器：
```
输入: 784维
FC1: 784 → 1024 (ReLU)
FC2: 1024 → channel (ReLU)
输出: channel维语义特征
```

解码器：
```
输入: channel维语义特征
FC1: channel → 1024 (ReLU)
FC2: 1024 → 784 (ReLU)
输出: 784维重建图像
```

其中 channel = 压缩率 × 784，本实验测试了三种压缩率：
- 压缩率0.1: channel=78
- 压缩率0.2: channel=157
- 压缩率0.3: channel=235

## 三、实验实施过程

### 3.1 系统部署

#### 步骤1：环境配置

1. 安装CUDA版本的PyTorch
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
```

2. 安装依赖包
```bash
pip install numpy matplotlib pandas scipy pillow
```

#### 步骤2：模型训练

**2.1 训练MNIST分类器**

```bash
cd semantic_extraction
python MLP_MNIST_model.py
```

训练结果：
- 训练轮数: 10 epochs
- 最终准确率: **98.5%**
- 模型保存: `saved_model/MLP_MNIST.pkl`

**2.2 训练语义编码器-解码器**

```bash
python MNIST.py
```

训练参数：
- 压缩率: 0.1, 0.2, 0.3
- 训练轮数: 150 epochs (每个压缩率)
- 信道SNR: 10dB
- 优化器: Adam (lr=1e-3 → 1e-4 → 1e-5)

训练结果：

| 压缩率 | 最终准确率 | PSNR (dB) | 语义特征维度 |
|--------|-----------|-----------|-------------|
| 0.1    | 98.4%     | 18.1      | 78          |
| 0.2    | 99.3%     | 18.7      | 157         |
| 0.3    | 99.3%     | 18.8      | 235         |

### 3.2 对抗攻击实现

实现了5种对抗攻击方法：

#### 1. FGSM攻击 (Fast Gradient Sign Method)

**原理**：单步梯度符号攻击

```python
# 计算梯度
loss = CrossEntropyLoss(model(image), true_label)
gradient = ∂loss/∂image

# 生成对抗样本
perturbation = ε × sign(gradient)
adversarial_image = image + perturbation
```

**特点**：
- 快速（单步）
- 计算效率高
- 攻击效果中等

#### 2. PGD攻击 (Projected Gradient Descent)

**原理**：迭代优化攻击

```python
# 初始化（可选随机起点）
adv_image = image + random_noise

# 迭代优化
for i in range(num_iterations):
    gradient = ∂loss/∂adv_image
    adv_image = adv_image + α × sign(gradient)
    
    # 投影到epsilon球内
    perturbation = clip(adv_image - image, -ε, ε)
    adv_image = image + perturbation
    adv_image = clip(adv_image, 0, 1)
```

**参数**：
- 迭代次数: 40
- 步长α: 0.01
- 扰动范围ε: 0.1, 0.2, 0.3

**特点**：
- 强大（迭代优化）
- 攻击成功率高
- 计算成本较高

#### 3. 端到端攻击

**原理**：优化整个语义通信流程

```python
loss = λ_class × classification_loss 
     - λ_recon × reconstruction_loss
```

**特点**：
- 考虑完整编码-解码-分类流程
- 平衡攻击效果和图像质量
- 扰动更优化

#### 4. 语义特征空间攻击

**原理**：直接在语义特征上添加扰动

```python
semantic_features = encoder(image)
perturbed_features = semantic_features + δ
adv_image = decoder(perturbed_features)
```

**特点**：
- 低维空间操作
- 扰动维度更小
- 针对性强

#### 5. 信道噪声攻击

**原理**：在信道中注入对抗噪声

**特点**：
- 更贴近实际攻击场景
- 不需修改发送端
- 可扩展性强

## 四、实验结果与分析

### 4.1 攻击效果对比

测试配置：
- 测试集: MNIST测试集 (100个样本)
- 模型: 压缩率0.1 (78维语义特征)
- 干净样本准确率: **99.0%**

#### FGSM攻击结果

| Epsilon | 对抗准确率 | 攻击成功率 | L2扰动 | L∞扰动 | PSNR (dB) | 语义距离 |
|---------|-----------|-----------|--------|--------|-----------|----------|
| 0.1     | 85.00%    | 15.00%    | 2.09   | 0.10   | 22.54     | 0.0443   |
| 0.2     | 36.00%    | **64.00%**| 4.14   | 0.20   | 16.59     | 0.0883   |
| 0.3     | 8.00%     | **92.00%**| 6.17   | 0.30   | 13.13     | 0.1320   |

**分析**：
- ε=0.1时攻击效果较弱（15%成功率）
- ε=0.2时攻击效果显著提升（64%成功率）
- ε=0.3时达到92%成功率，但图像质量明显下降

#### PGD攻击结果

| Epsilon | 对抗准确率 | 攻击成功率 | L2扰动 | L∞扰动 | PSNR (dB) | 语义距离 |
|---------|-----------|-----------|--------|--------|-----------|----------|
| 0.1     | 69.00%    | 31.00%    | 2.07   | 0.10   | 22.62     | 0.0436   |
| 0.2     | 2.00%     | **98.00%**| 4.01   | 0.20   | 16.87     | 0.0894   |
| 0.3     | 0.00%     | **100.00%**| 5.53  | 0.30   | 14.08     | 0.1215   |

**分析**：
- PGD攻击明显强于FGSM
- ε=0.2时达到98%成功率
- **ε=0.3时实现100%攻击成功率**，完全破坏分类系统

#### 端到端攻击结果

| 配置 | 对抗准确率 | 攻击成功率 | L2扰动 | L∞扰动 | PSNR (dB) | 语义距离 |
|------|-----------|-----------|--------|--------|-----------|----------|
| ε=0.3, 40 iter | 76.00% | 24.00% | **1.28** | 0.30 | **20.86** | **0.0515** |

**分析**：
- 攻击成功率相对较低（24%）
- 但扰动最优化（L2=1.28，最小）
- 图像质量保持最好（PSNR=20.86）
- 语义特征变化最小（0.0515）

### 4.2 可视化结果分析

#### FGSM攻击示例 (ε=0.3)

观察到的攻击效果：
- 数字 **2 → 3** (分类错误)
- 数字 **1 → 8** (分类错误)
- 数字 **0 → 7** (分类错误)
- 数字 **4 → 9** (分类错误)
- 数字 **7 → 7** (分类正确，攻击失败)

**特征**：
- 对抗样本视觉上有明显噪声
- 扰动分布不均匀
- 部分样本攻击失败

#### PGD攻击示例 (ε=0.3)

观察到的攻击效果：
- 数字 **7 → 0** (分类错误)
- 数字 **2 → 8** (分类错误)
- 数字 **1 → 6** (分类错误)
- 数字 **0 → 9** (分类错误)
- 数字 **4 → 9** (分类错误)

**特征**：
- **所有样本全部攻击成功**
- 扰动更加优化和均匀
- 视觉上仍有噪声但分布更均匀

### 4.3 关键发现

#### 1. 语义通信系统的脆弱性

**高度脆弱**：
- PGD攻击在ε=0.3时达到**100%成功率**
- 相对较小的扰动（ε=0.2）即可实现64-98%成功率
- 语义特征对输入扰动非常敏感

#### 2. 攻击方法效果排序

```
PGD攻击 > FGSM攻击 > 端到端攻击
(100%)    (92%)      (24%)
```

#### 3. 扰动大小与攻击成功率的权衡

| ε值 | 攻击成功率 | 图像质量(PSNR) | 实际可行性 |
|-----|-----------|----------------|-----------|
| 0.1 | 低(15-31%)| 高(>22dB)      | 不实用    |
| 0.2 | 高(64-98%)| 中等(~16dB)    | **最佳平衡** |
| 0.3 | 极高(92-100%)| 较差(~13dB) | 易被察觉  |

**结论**：ε=0.2是攻击效果和隐蔽性的最佳平衡点

#### 4. 语义特征的不稳定性

语义距离变化：
- FGSM (ε=0.3): 0.1320
- PGD (ε=0.3): 0.1215
- 端到端: 0.0515

**发现**：即使小的输入扰动也能显著改变语义特征，说明当前的语义编码器缺乏鲁棒性。

## 五、安全威胁分析

### 5.1 实际应用场景的威胁

#### 智慧城市
- **监控系统**：人脸识别被欺骗，无法识别嫌疑人
- **交通管理**：车牌识别错误，导致违章处理失误

#### 自动驾驶
- **交通标志识别**：停车标志被误识别为限速标志
- **行人检测**：对抗样本导致行人检测失败
- **潜在后果**：交通事故、人员伤亡

#### 医疗诊断
- **医学影像分析**：肿瘤识别错误
- **疾病诊断**：误诊或漏诊
- **潜在后果**：延误治疗、医疗事故

#### 工业检测
- **产品质量检测**：缺陷检测失效
- **设备监控**：故障识别错误

### 5.2 攻击成本与可行性

**白盒攻击**（本实验场景）：
- 前提：完全了解模型结构和参数
- 计算成本：低（秒级生成对抗样本）
- 成功率：极高（PGD可达100%）
- 实际可行性：中等（需要内部信息）

**黑盒攻击**（更现实场景）：
- 前提：仅能查询模型
- 计算成本：中等
- 成功率：较高（通过迁移攻击）
- 实际可行性：高

## 六、防御策略探索

### 6.1 对抗训练

**原理**：在训练过程中加入对抗样本

```python
for epoch in epochs:
    # 生成对抗样本
    adv_images = generate_adversarial(images)
    
    # 混合训练
    loss = loss(model(images), labels) 
         + loss(model(adv_images), labels)
```

**优点**：
- 显著提高模型鲁棒性
- 直接增强防御能力

**缺点**：
- 训练成本增加2-3倍
- 可能降低干净样本准确率

### 6.2 输入预处理

**方法**：
1. **随机化**：添加随机噪声
2. **平滑**：高斯模糊、中值滤波
3. **压缩**：JPEG压缩

**优点**：
- 实现简单
- 计算开销小

**缺点**：
- 可能被自适应攻击绕过
- 会降低图像质量

### 6.3 对抗样本检测

**方法**：
1. **统计检测**：检测异常的激活模式
2. **置信度检测**：低置信度样本标记
3. **重构误差**：对抗样本重构误差较大

**优点**：
- 不修改主模型
- 可作为额外安全层

**缺点**：
- 可能产生误报
- 可被针对性攻击

### 6.4 增加语义特征维度

**假设**：更高维的语义特征可能更鲁棒

**实验建议**：
- 测试压缩率0.2、0.3下的攻击效果
- 对比不同压缩率的防御能力

### 6.5 集成防御

**策略**：结合多种防御方法

```
输入 → 预处理 → 对抗训练模型 → 检测器 → 输出
```

**优点**：
- 多层防御，更难攻破
- 提高整体安全性

## 七、实验总结与展望

### 7.1 主要成果

1. **成功部署**：实现了完整的MNIST语义通信系统
   - 3种压缩率模型（0.1, 0.2, 0.3）
   - 最高准确率99.3%

2. **攻击实现**：实现了5种对抗攻击方法
   - FGSM攻击
   - PGD攻击（最高100%成功率）
   - 端到端攻击
   - 语义特征空间攻击
   - 信道噪声攻击

3. **安全性评估**：量化分析了系统脆弱性
   - PGD攻击可完全破坏系统（100%成功率）
   - 发现最佳攻击参数（ε=0.2）
   - 揭示语义特征的不稳定性

4. **可视化结果**：生成了清晰的攻击效果展示
   - FGSM攻击可视化
   - PGD攻击可视化
   - 扰动模式分析

### 7.2 创新点

1. **系统化评估**：首次对该语义通信系统进行全面的对抗攻击评估
2. **多维度分析**：从攻击成功率、扰动大小、图像质量、语义距离等多个维度评估
3. **实用性考量**：分析了ε=0.2作为最佳攻击参数的实际意义

### 7.3 局限性

1. **测试数据集**：仅在MNIST数据集上测试，结论的普适性有待验证
2. **攻击场景**：主要为白盒攻击，黑盒攻击未实现
3. **防御验证**：提出了防御策略但未实际实现和验证
4. **压缩率影响**：仅详细测试了压缩率0.1，其他压缩率的结果待补充

### 7.4 未来工作方向

#### 短期目标（可扩展的实验内容）

1. **不同压缩率测试**
   - 对压缩率0.2、0.3进行完整攻击测试
   - 分析压缩率与鲁棒性的关系

2. **信道鲁棒性测试**
   - 测试不同SNR下的攻击效果
   - 分析信道噪声对对抗样本的影响

3. **黑盒攻击实现**
   - 基于查询的黑盒攻击
   - 迁移攻击（训练替代模型）

4. **防御方法实现**
   - 实现对抗训练
   - 测试输入预处理的效果
   - 评估防御方法的有效性

#### 长期目标（研究方向）

1. **扩展到其他数据集**
   - CIFAR-10（彩色图像）
   - ImageNet（复杂场景）
   - 医疗影像数据集

2. **真实场景验证**
   - 物理世界对抗样本
   - 端到端通信系统测试

3. **理论分析**
   - 语义通信系统的鲁棒性理论界限
   - 压缩与鲁棒性的本质关系

4. **新型防御机制**
   - 基于认证的防御
   - 鲁棒的语义编码方法
   - 自适应防御策略

## 八、参考文献

[1] Zhang, H., Shao, S., Tao, M., Bi, X., & Letaief, K. B. (2023). Deep Learning-Enabled Semantic Communication Systems With Task-Unaware Transmitter and Dynamic Data. *IEEE Journal on Selected Areas in Communications*, 41(1), 170-185.

[2] Goodfellow, I. J., Shlens, J., & Szegedy, C. (2015). Explaining and Harnessing Adversarial Examples. *ICLR 2015*.

[3] Madry, A., Makelov, A., Schmidt, L., Tsipras, D., & Vladu, A. (2018). Towards Deep Learning Models Resistant to Adversarial Attacks. *ICLR 2018*.

[4] Carlini, N., & Wagner, D. (2017). Towards Evaluating the Robustness of Neural Networks. *IEEE Symposium on Security and Privacy*.

[5] Is Semantic Communications Secure? A Tale of Multi-Domain Adversarial Attacks. (对抗攻击综述论文)

## 附录

### A. 代码结构

```
项目根目录/
├── semantic_extraction/          # 语义提取模块
│   ├── MLP_MNIST_model.py       # 分类器训练
│   ├── MNIST.py                 # 编码器训练
│   └── results/                 # 训练结果
├── attacks/                      # 对抗攻击模块
│   ├── fgsm.py                  # FGSM攻击
│   ├── pgd.py                   # PGD攻击
│   ├── semantic_attack.py       # 语义空间攻击
│   └── evaluate.py              # 评估工具
├── saved_model/                  # 训练好的模型
│   ├── MLP_MNIST.pkl            # 分类器
│   └── MLP_MNIST_coder_*.pkl    # 编码器-解码器
├── test_attack.py               # 攻击测试脚本
├── attack_results_fgsm.png      # FGSM攻击可视化
├── attack_results_pgd.png       # PGD攻击可视化
└── ATTACK_RESULTS_SUMMARY.md    # 详细结果报告
```

### B. 实验数据

**训练时间统计**：
- 分类器训练：约5分钟（10 epochs）
- 语义编码器训练：约2小时（3个模型 × 150 epochs）
- 对抗攻击测试：约10分钟

**计算资源消耗**：
- GPU内存：约2-3GB
- 训练总耗时：约2.5小时
- 对抗样本生成：秒级

### C. 使用说明

**运行对抗攻击测试**：
```bash
python test_attack.py
```

**测试不同压缩率**：
修改 `test_attack.py` 中的 `compression_rate` 参数

**自定义攻击参数**：
```python
from attacks import pgd_attack_semantic

adv_images, perturbation = pgd_attack_semantic(
    encoder, decoder, classifier,
    images, labels,
    epsilon=0.2,      # 扰动大小
    alpha=0.01,       # 步长
    num_iter=40       # 迭代次数
)
```


